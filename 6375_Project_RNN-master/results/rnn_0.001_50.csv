Epochs,Training loss,Validation loss
1,4.714474201202393,3.3385889530181885
2,3.3633406162261963,3.2987704277038574
3,3.3290367126464844,3.275470495223999
4,3.2985708713531494,3.2461891174316406
5,3.267047882080078,3.2142763137817383
6,3.232872247695923,3.1795341968536377
7,3.2001144886016846,3.148715019226074
8,3.167525053024292,3.1191720962524414
9,3.1376826763153076,3.0930886268615723
10,3.1111464500427246,3.0695648193359375
11,3.086789608001709,3.047426462173462
12,3.0633041858673096,3.0249948501586914
13,3.035198926925659,2.9847755432128906
14,2.9556429386138916,2.9146223068237305
15,2.9282920360565186,2.900373935699463
16,2.913013219833374,2.8866782188415527
17,2.8984856605529785,2.8735108375549316
18,2.884551763534546,2.860848903656006
19,2.871159076690674,2.8486521244049072
20,2.8604373931884766,2.852663040161133
21,2.8873395919799805,2.872467279434204
22,2.896743059158325,2.883009433746338
23,2.8956432342529297,2.879509687423706
24,2.8902087211608887,2.876450300216675
25,2.887676954269409,2.8681139945983887
26,2.8801279067993164,2.8612303733825684
27,2.890643358230591,2.878593683242798
28,2.890524387359619,2.866928815841675
29,2.8776283264160156,2.855276107788086
30,2.8653624057769775,2.8443257808685303
31,2.8538289070129395,2.833733081817627
32,2.8429503440856934,2.823538303375244
33,2.83284068107605,2.8144896030426025
34,2.823577880859375,2.8062171936035156
35,2.8150455951690674,2.7985942363739014
36,2.8070216178894043,2.7912421226501465
37,2.7993383407592773,2.7842540740966797
38,2.791224718093872,2.7755067348480225
39,2.768827438354492,2.750504970550537
40,2.75312876701355,2.7420670986175537
41,2.7443413734436035,2.73429012298584
42,2.7365245819091797,2.7269203662872314
43,2.729269504547119,2.7199182510375977
44,2.7223920822143555,2.7132327556610107
45,2.7156617641448975,2.7065317630767822
46,2.708911180496216,2.6999354362487793
47,2.7020649909973145,2.692422389984131
48,2.694180488586426,2.684087038040161
49,2.6845545768737793,2.674095392227173
50,2.6733973026275635,2.664246082305908
